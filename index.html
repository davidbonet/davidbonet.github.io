<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>David Bonet</title>
  
  <meta name="author" content="David Bonet">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon_web.png">
  <script src="hidebib.js" type="text/javascript"></script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        
      
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>David Bonet</name>
              </p>
              <p>I am a MSc student at <a href="https://www.upc.edu/en?set_language=en">Universitat Politècnica de Catalunya (UPC)</a>, majoring in Deep Learning for Multimedia Processing. Before that, I received my Bachelor's degree in Telecommunications Engineering at UPC.
              </p>
              <p>
                I was a visiting researcher at <a href="https://viterbischool.usc.edu/">USC Viterbi</a>, working in <a href="https://sites.google.com/usc.edu/stac-lab/home?authuser=1">Prof. Antonio Ortega's lab</a>. 
                Previously, I worked in <a href="https://www.telefonica.com/en/web/innovation/core-innovation/research">Telefónica Research</a>, supervised by <a href="https://www.linkedin.com/in/jordi-luque-0736b47/">Jordi Luque</a> and <a href="https://www.linkedin.com/in/carlos-segura-perales-80677765/">Carlos Segura</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:davidbonetsole@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=ryl2ZnUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/davidbonet/">Github</a> &nbsp/&nbsp
                <a href="https://linkedin.com/in/davidbonetsole/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/DavidBonet.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/DavidBonet_circle_nobackg.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in machine learning, computer vision, speech processing, and neural network interpretability. 
                Also, I aim to build systems capable of learning models of the world in a multimodal way and with little to no manual supervision.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          

          <td width="15%" valign="center" align="center"><img src="images/cwnnk.png" alt="nthu" width="200"></td>
          </td>
          <td width="85%" style="padding:20px;vertical-align:middle">
            <a class="tog" href="https://arxiv.org/pdf/2107.12972.pdf">
              <papertitle>Channel Redundancy and Overlap in Convolutional Neural Networks with Channel-Wise NNK Graphs</papertitle>
            </a>
            <br>
            <strong>David Bonet</strong>,
                    <a href="https://scholar.google.com/citations?user=K4bCJYcAAAAJ&hl=en" target="_blank">Antonio Ortega</a>,
                    <a href="https://scholar.google.es/citations?user=1eAA6ggAAAAJ&hl=en" target="_blank">Javier Ruiz-Hidalgo</a>,
                    <a href="https://shekkizh.github.io/" target="_blank">Sarath Shekkizhar</a>
                    <br>
            <p></p>
            <em>Under review for IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2021
            <div class="paper" id="bonet2021redundancy">
              paper /
                <a class="tog" href="javascript:toggleblock('cwnnk_abs')">abstract</a> / 
                bibtex
                <p align="justify">
                  <i id="cwnnk_abs">
                    Feature spaces in the deep layers of convolutional neural networks (CNNs) are often very high-dimensional and difficult to interpret. However, convolutional layers consist of multiple channels that are activated by different types of inputs, which suggests that more insights may be gained by studying the channels and how they relate to each other. In this paper, we first analyze theoretically channel-wise non-negative kernel (CW-NNK) regression graphs, which allow us to quantify the overlap between channels and, indirectly, the intrinsic dimension of the data representation manifold. We find that redundancy between channels is significant and varies with the layer depth and the level of regularization during training. Additionally, we observe that there is a correlation between channel overlap in the last convolutional layer and generalization performance. Our experimental results demonstrate that these techniques can lead to a better understanding of deep representations. 
                  </i>
                </p>
              </div>              
              <script language="JavaScript">hideblock('cwdeepnnk_abs');</script>
          </td>
          </tr>




          <td width="15%" valign="center" align="center"><img src="images/cwdeepnnk.png" alt="nthu" width="200"></td>
          </td>
          <td width="85%" style="padding:20px;vertical-align:middle">
            <a class="tog" href="https://arxiv.org/pdf/2107.12972.pdf">
              <papertitle>Channel-Wise Early Stopping without a Validation Set via NNK Polytope Interpolation</papertitle>
            </a>
            <br>
            <strong>David Bonet</strong>,
                    <a href="https://scholar.google.com/citations?user=K4bCJYcAAAAJ&hl=en" target="_blank">Antonio Ortega</a>,
                    <a href="https://scholar.google.es/citations?user=1eAA6ggAAAAJ&hl=en" target="_blank">Javier Ruiz-Hidalgo</a>,
                    <a href="https://shekkizh.github.io/" target="_blank">Sarath Shekkizhar</a>
                    <br>
            <p></p>
            <em>Asia Pacific Signal and Information Processing Association (APSIPA)</em>, 2021
            <div class="paper" id="bonet2021channel">
              <a href="https://arxiv.org/pdf/2107.12972.pdf" target="_blank">paper</a> /
              <a href="https://github.com/STAC-USC/CW-DeepNNK_Early_Stopping" target="_blank">code</a> /  
                <a class="tog" href="javascript:toggleblock('cwdeepnnk_abs')">abstract</a> / 
                <a class="tog" href="javascript:toggleblock('cwdeepnnk_bib')">bibtex</a>
                <p align="justify">
                  <i id="cwdeepnnk_abs">
                    State-of-the-art neural network architectures continue to scale in size and deliver impressive generalization results, although this comes at the expense of limited interpretability. In particular, a key challenge is to determine when to stop training the model, as this has a significant impact on generalization. Convolutional neural networks (ConvNets) comprise high-dimensional feature spaces formed by the aggregation of multiple channels, where analyzing intermediate data representations and the model's evolution can be challenging owing to the curse of dimensionality. We present channel-wise DeepNNK (CW-DeepNNK), a novel channel-wise generalization estimate based on non-negative kernel regression (NNK) graphs with which we perform local polytope interpolation on low-dimensional channels. This method leads to instance-based interpretability of both the learned data representations and the relationship between channels. Motivated by our observations, we use CW-DeepNNK to propose a novel early stopping criterion that (i) does not require a validation set, (ii) is based on a task performance metric, and (iii) allows stopping to be reached at different points for each channel. Our experiments demonstrate that our proposed method has advantages as compared to the standard criterion based on validation set performance.
                  </i>
                </p>
                <bibtext xml:space="preserve" id="cwdeepnnk_bib">
                                      @article{bonet2021channel, <br />
                                        title={Channel-Wise Early Stopping without a Validation Set via NNK Polytope Interpolation}, <br />
                                        author={Bonet, David and Ortega, Antonio and Ruiz-Hidalgo, Javier and Shekkizhar, Sarath}, <br />
                                        journal={Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, <br />
                                        year={2021} <br />
                                      }
                  </bibtext>
              </div>              
              <script language="JavaScript">hideblock('cwdeepnnk_bib');hideblock('cwdeepnnk_abs');</script>
          </td>
          </tr>

          <td width="15%" valign="center" align="center"><img src="images/sewuw.png" alt="nthu" width="200"></td>
          </td>
          <td width="85%" style="padding:20px;vertical-align:middle">
            <a class="tog" href="https://www.isca-speech.org/archive/pdfs/iberspeech_2021/bonet21_iberspeech.pdf">
              <papertitle>Speech Enhancement for Wake-Up-Word detection in Voice Assistants</papertitle>
            </a>
            <br>
            <strong>David Bonet</strong>,
                    <a href="https://www.linkedin.com/in/guillermocambara/" target="_blank">Guillermo Cámbara</a>,
                    <a href="https://www.linkedin.com/in/wiliam-fernando-l%C3%B3pez-gavil%C3%A1nez-956410153/" target="_blank">Fernando López</a>,
                    <a href="https://www.linkedin.com/in/pablo-gomez-guerrero/" target="_blank">Pablo Gómez</a>,
                    <a href="https://www.linkedin.com/in/carlos-segura-perales-80677765/" target="_blank">Carlos Segura</a>,
                    <a href="https://www.linkedin.com/in/mireia-farr%C3%BAs-9b767b7/" target="_blank">Mireia Farrús</a>,
                    <a href="https://www.linkedin.com/in/jordi-luque-0736b47/" target="_blank">Jordi Luque</a>
                    <br>
            <p></p>
            <em>IberSPEECH</em>, 2020. <strong>Best regular paper award</strong> <small>(1 of 15 awardees)</small>
            <div class="paper" id="bonet21_iberspeech">
              <a href="https://www.isca-speech.org/archive/pdfs/iberspeech_2021/bonet21_iberspeech.pdf" target="_blank">paper</a> /
                <a class="tog" href="javascript:toggleblock('sewuw_abs')">abstract</a> / 
                <a class="tog" href="javascript:toggleblock('sewuw_bib')">bibtex</a>
                <p align="justify">
                  <i id="sewuw_abs">
                    Keyword spotting and in particular Wake-Up-Word (WUW) detection is a very important task for voice assistants. A very common issue of voice assistants is that they get easily activated by background noise like music, TV or background speech that accidentally triggers the device. In this paper, we propose a Speech Enhancement (SE) model adapted to the task of WUW detection that aims at increasing the recognition rate and reducing the false alarms in the presence of these types of noises. The SE model is a fully-convolutional denoising auto-encoder at waveform level and is trained using a log-Mel Spectrogram and waveform reconstruction losses together with the BCE loss of a simple WUW classification network. A new database has been purposely prepared for the task of recognizing the WUW in challenging conditions containing negative samples that are very phonetically similar to the keyword. The database is extended with public databases and an exhaustive data augmentation to simulate different noises and environments. The results obtained by concatenating the SE with a simple and state-of-the-art WUW detectors show that the SE does not have a negative impact on the recognition rate in quiet environments while increasing the performance in the presence of noise, especially when the SE and WUW detector are trained jointly end-to-end.
                  </i>
                </p>
                <bibtext xml:space="preserve" id="sewuw_bib">
                                      @inproceedings{bonet21_iberspeech, <br />
                                        author={David Bonet and Guillermo Cámbara and Fernando López and Pablo Gómez and Carlos Segura and Jordi Luque and Mireia Farrús}, <br />
                                        title={{Speech Enhancement for Wake-Up-Word detection in Voice Assistants}}, <br />
                                        year=2021, <br />
                                        booktitle={Proc. IberSPEECH 2021}, <br />
                                        pages={41--45}, <br />
                                        doi={10.21437/IberSPEECH.2021-9} <br />
                                      }
                  </bibtext>
              </div>              
              <script language="JavaScript">hideblock('sewuw_bib');hideblock('sewuw_abs');</script>
          </td>
          </tr>




        <td width="15%" valign="center" align="center"><img src="images/bcn2brno.png" alt="nthu" width="180"></td>
        </td>
        <td width="85%" style="padding:20px;vertical-align:middle">
          <a class="tog" href="https://www.isca-speech.org/archive/pdfs/iberspeech_2021/kocour21_iberspeech.pdf">
            <papertitle>BCN2BRNO: ASR System Fusion for Albayzin 2020 Speech to Text Challenge</papertitle>
          </a>
          <br>
                  <a href="https://www.linkedin.com/in/martinkocour/" target="_blank">Martin Kocour</a>,
                  <a href="https://www.linkedin.com/in/guillermocambara/" target="_blank">Guillermo Cámbara</a>,
                  <a href="https://www.linkedin.com/in/jordi-luque-0736b47/" target="_blank">Jordi Luque</a>,
                  <strong>David Bonet</strong>,
                  <a href="https://www.linkedin.com/in/mireia-farr%C3%BAs-9b767b7/" target="_blank">Mireia Farrús</a>,
                  <a href="https://scholar.google.com/citations?user=qNo33PkAAAAJ&hl=en&oi=ao" target="_blank">Martin Karafiat</a>,
                  <a href="https://scholar.google.com/citations?user=BpPsV98AAAAJ&hl=en" target="_blank">Karel Veselý</a>,
                  <a href="https://scholar.google.com/citations?user=BnfCLXcAAAAJ&hl=en&oi=sra" target="_blank">Jan Cernocky</a>
                  <br>
          <p></p>
          <em>IberSPEECH</em>, 2020
          <div class="paper" id="kocour21_iberspeech">
            <a href="https://www.isca-speech.org/archive/pdfs/iberspeech_2021/kocour21_iberspeech.pdf" target="_blank">paper</a> /
              <a class="tog" href="javascript:toggleblock('bcn2brno_abs')">abstract</a> / 
              <a class="tog" href="javascript:toggleblock('bcn2brno_bib')">bibtex</a>
              <p align="justify">
                <i id="bcn2brno_abs">
                  This paper describes the joint effort of BUT and Telefónica Research on the development of Automatic Speech Recognition systems for the Albayzin 2020 Challenge. We compare approaches based on either hybrid or end-to-end models. In hybrid modelling, we explore the impact of a SpecAugment layer on performance. For end-to-end modelling, we used a convolutional neural network with gated linear units (GLUs). The performance of such model is also evaluated with an additional n-gram language model to improve word error rates. We further inspect source separation methods to extract speech from noisy environments (i.e. TV shows). More precisely, we assess the effect of using a neural-based music separator named Demucs. A fusion of our best systems achieved 23.33 % WER in official Albayzin 2020 evaluations. Aside from techniques used in our final submitted systems, we also describe our efforts in retrieving high-quality transcripts for training.
                </i>
              </p>
              <bibtext xml:space="preserve" id="bcn2brno_bib">
                                    @inproceedings{kocour21_iberspeech, <br />
                                      author={Martin Kocour and Guillermo Cámbara and Jordi Luque and David Bonet and Mireia Farrús and Martin Karafiát and Karel Veselý and Jan Černocký}, <br />
                                      title={{BCN2BRNO: ASR System Fusion for Albayzin 2020 Speech to Text Challenge}}, <br />
                                      year=2021, <br />
                                      booktitle={Proc. IberSPEECH 2021}, <br />
                                      pages={113--117}, <br />
                                      doi={10.21437/IberSPEECH.2021-24} <br />
                                    }
                </bibtext>
            </div>              
            <script language="JavaScript">hideblock('bcn2brno_bib');hideblock('bcn2brno_abs');</script>
        </td>
        </tr>

					


        </tbody></table>




      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Theses</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <td width="15%" valign="center" align="center"><img src="images/bsthesis.png" alt="nthu" width="200"></td>
        </td>
        <td width="85%" style="padding:20px;vertical-align:middle">
          <a class="tog" href="https://imatge.upc.edu/web/sites/default/files/pub/xBonet21.pdf">
            <papertitle>Improved Neural Network Generalization using Channel-Wise NNK Graph Constructions</papertitle>
          </a>
          <br>
          Bachelor's Thesis
          <br>
          <strong>David Bonet</strong>
          <br>
          <p></p>
          <em>Universitat Politècnica de Catalunya (UPC), 2021</em>
          <div class="paper" id="Bonet2021BThesis">
            <a href="https://imatge.upc.edu/web/sites/default/files/pub/xBonet21.pdf" target="_blank">PDF</a> /
              <a class="tog" href="javascript:toggleblock('Bonet2021BThesis_bib')">bibtex</a>
              <p align="justify">
              <bibtext xml:space="preserve" id="Bonet2021BThesis_bib">
                                  @mastersthesis{Bonet2021BThesis, <br />
                                      author = {David Bonet}, <br />
                                      title = {Improved Neural Network Generalization using Channel-Wise NNK Graph Constructions}, <br />
                                      school = {Universitat Politècnica de Catalunya}, <br />
                                      address = {Barcelona (Spain)}, <br />
                                      year = {2021}, <br />
                                      type = "{B.S. Thesis}", <br />
                                  }
                </bibtext>
            </div>              
            <script language="JavaScript">hideblock('Bonet2021BThesis_bib');</script>
        </td>
        </tr>

      
      </tbody></table>


      <br>
      <br>
  

      <table width="100%" border="0" cellspacing="15" cellpadding="10">
        <heading>&nbsp;&nbsp;&nbsp;Education</heading>
    
        <tr>
          <td width="15%" valign="center" align="center"><img src="images/UPC_logo.png" alt="nthu" width="110"></td>
          <td width="85%" valign="top">
          <p>
            <span><strong><a href="https://matt.masters.upc.edu/">Master's in Advanced Telecommunication Technologies (MATT)</a></strong></span><span style="float:right">September 2021 - Present</span> <br>
            Major in Deep Learning for Multimedia Processing
            <br>
            <em><a href="https://www.upc.edu/en?set_language=en" target="_blank">Universitat Politècnica de Catalunya (UPC)</a></em>
            <br>
            Barcelona, Spain
          </p>
          </td>
        </tr>
    
        <tr>
          <td width="15%" valign="center" align="center"><img src="images/usc_logo.png" alt="nthu" width="110"></td>
          <td width="85%" valign="top">
          <p>
            <span><strong>Visiting Researcher at USC Viterbi</strong></span><span style="float:right">January 2021 - August 2021</span> <br>
            <em><a href="https://viterbischool.usc.edu/" target="_blank">University of Southern California (USC)</a></em>
            <br>
            
            Advisor: <a href="https://scholar.google.com/citations?user=K4bCJYcAAAAJ&hl=en" target="_blank"> Professor Antonio Ortega</a>
            <br>
            Los Angeles, USA
            <br>
          </p>
          </td>
        </tr>
        
        <tr>
          <td width="15%" valign="center" align="center"><img src="images/UPC_logo.png" alt="nthu" width="110"></td>
          <td width="85%" valign="top">
          <p>
            <span><strong><a href="https://telecos.upc.edu/en/study-programs/the-studies?set_language=en">Bachelor's in Telecommunications Engineering</a></strong></span><span style="float:right">September 2017 - July 2021</span> <br>
            Major in Audiovisual Systems
            <br>
            <em><a href="https://www.upc.edu/en?set_language=en" target="_blank">Universitat Politècnica de Catalunya (UPC)</a></em>
            <br>
            Barcelona, Spain
          </p>
          </td>
        </tr>

        </table>


        <table width="100%" border="0" cellspacing="15" cellpadding="10">
          <heading>&nbsp;&nbsp;&nbsp;Experience</heading>
      
          <tr>
            <td width="15%" valign="center" align="center"><img src="images/telefonica.png" alt="nthu" width="110"></td>
            <td width="85%" valign="top">
            <p>
              <span><strong>Research Intern</strong></span><span style="float:right">July 2020 - December 2020</span> <br>
              <em><a href="https://www.telefonica.com/en/web/innovation/core-innovation/research" target="_blank">Telefónica Research</a></em>
              <br>
              Supervisors: <a href="https://www.linkedin.com/in/jordi-luque-0736b47/">Jordi Luque</a> and <a href="https://www.linkedin.com/in/carlos-segura-perales-80677765/">Carlos Segura</a>
              <br>
              <br>
              During this internship, I developed a speech enhancement system for wake-up-word detection in Telefónica's voice assistant (Aura) and contributed to the creation of a new database for the task. 
              Additionally, I collaborated with the Brno University of Technology in developing an automatic speech recognition system.
              <br>
              <br>
              Barcelona, Spain
            </p>
            </td>
          </tr>
      
          <tr>
            <td width="15%" valign="center" align="center"><img src="images/cern_ideasquare.png" alt="nthu" width="110"></td>
            <td width="85%" valign="top">
            <p>
              <span><strong>Challenge Based Innovation (CBI) Program</strong></span><span style="float:right">September 2020 - January 2021</span> <br>
              <em><a href="https://ideasquare.cern/home" target="_blank">CERN IdeaSquare</a></em>
              <br>
              <br>
              Carried out a global multidisciplinary project at CERN jointly with ESADE MBA, IED and UPC students with the help of researchers at CERN. 
              Specifically, we tackled the information sharing and validation problem due to the COVID-19 pandemic by creating a prototype application to strengthen source validation and build resilience against disinformation practices.
              <br>
              <br>
              Barcelona, Spain and Geneva, Switzerland
            </p>
            </td>
          </tr>
          </table>
  




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <p style="text-align:right;font-size:small;">
                This template is a modification to Jon Barron's <a href="https://jonbarron.info/">website</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
